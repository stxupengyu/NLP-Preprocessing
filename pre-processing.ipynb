{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取npz格式的数据\n",
    "data=np.load('dfdata.npz',allow_pickle=True)\n",
    "body=data['body']\n",
    "tag=data['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_body(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    sentence = re.sub(cleanr, ' ', sentence)        #去除html标签\n",
    "    sentence=sentence.lower()\n",
    "    del_estr = string.punctuation + string.digits+string.whitespace  # 去除ASCII 标点符号，数字\n",
    "    replace = \" \"*len(del_estr)\n",
    "    tran_tab = str.maketrans(del_estr, replace)\n",
    "    sentence = sentence.translate(tran_tab)\n",
    "    words=sentence.split(' ')\n",
    "    while '' in words:\n",
    "        words.remove('')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tag(sentence):\n",
    "    sentence=sentence.lower()\n",
    "    del_estr = string.punctuation + string.digits+string.whitespace  # 去除ASCII 标点符号，数字\n",
    "    replace = \" \"*len(del_estr)\n",
    "    tran_tab = str.maketrans(del_estr, replace)\n",
    "    sentence = sentence.translate(tran_tab)\n",
    "    words=sentence.split(' ')\n",
    "    while '' in words:\n",
    "        words.remove('')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end', 'syntax']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2=[]\n",
    "for tagi in tag:\n",
    "    tag2.append(remove_tag(tagi))\n",
    "tag3=[]\n",
    "for tagi in tag2:\n",
    "    tag3=tag3+tagi\n",
    "tag3[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "# 统计单词出现的频率\n",
    "counter = collections.Counter()\n",
    "for word in tag3:\n",
    "    counter[word] += 1#词频字典\n",
    "# 按照词频顺序对单词进行排序\n",
    "sorted_word_to_cnt = sorted(counter.items(), key=itemgetter(1), reverse=True)\n",
    "sorted_words = [x[0] for x in sorted_word_to_cnt]\n",
    "import codecs\n",
    "import sys\n",
    "# 读取词汇表，并建立词汇到单词编号的映射。\n",
    "vocab = sorted_words \n",
    "word_to_id = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\n",
    "# 如果出现了被删除的低频词，则替换为\"<unk>\"。\n",
    "def get_id(word):\n",
    "    return word_to_id[word] if word in word_to_id else word_to_id[\"<unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([31, 32, 62]), list([9, 16, 17, 50, 49, 87, 18, 382]),\n",
       "       list([163, 55]), ..., list([28, 3, 20, 68, 383]),\n",
       "       list([6, 4, 12, 15, 225]), list([18, 14])], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag5=[]\n",
    "for word in tag2:\n",
    "    tag4=[]\n",
    "    for w in word: \n",
    "        tag4=tag4+[get_id(w)]\n",
    "    tag5=tag5+[tag4]\n",
    "tag6=np.array(tag5)\n",
    "tag6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body2=[]\n",
    "for bodyi in body:\n",
    "    body2.append(remove_body(bodyi))\n",
    "body3=[]\n",
    "for bodyi in body2:\n",
    "    body3=body3+bodyi\n",
    "body3[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "# 统计单词出现的频率\n",
    "counter2 = collections.Counter()\n",
    "for word in body3:\n",
    "    counter2[word] += 1#词频字典\n",
    "# 按照词频顺序对单词进行排序\n",
    "sorted_word_to_cnt2 = sorted(counter2.items(), key=itemgetter(1), reverse=True)\n",
    "sorted_words2 = [x[0] for x in sorted_word_to_cnt2]\n",
    "import codecs\n",
    "import sys\n",
    "# 读取词汇表，并建立词汇到单词编号的映射。\n",
    "vocab2 = sorted_words2\n",
    "word_to_id2 = {k: v for (k, v) in zip(vocab2, range(len(vocab2)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果出现了被删除的低频词，则替换为\"<unk>\"。\n",
    "def get_id2(word):\n",
    "    return word_to_id2[word] if word in word_to_id2 else word_to_id2[\"<unk\"]\n",
    "body5=[]\n",
    "for word in body2:\n",
    "    body4=[]\n",
    "    for w in word: \n",
    "        body4=body4+[get_id2(w)]\n",
    "    body5=body5+[body4]\n",
    "body6=np.array(body5)\n",
    "body6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brs=body6#contextual\n",
    "ms=tag6#no useful\n",
    "sfs=tag6#tags \n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'tags':sfs,\n",
    "        'posts':brs,\n",
    "        'nouseful':ms,\n",
    "    }\n",
    ")\n",
    "df.tail()\n",
    "np.savez('data.npz',brs= brs, ms = ms,sfs=ms,allow_pickle=True)\n",
    "data=np.load('data.npz',allow_pickle=True)\n",
    "data['brs'][0],data['ms'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "share={word_to_id2[x]:word_to_id[x] for x in word_to_id2 if x in word_to_id}\n",
    "with open(\"shared.txt\",\"w\") as f:\n",
    "        f.write(str(share)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('temp.txt','w')\n",
    "#f.write(str(dict_name))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
