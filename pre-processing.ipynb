{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取npz格式的数据 先处理tag数据 因为数据小一点快一些\n",
    "data=np.load('dfdata.npz',allow_pickle=True)\n",
    "body=data['body']\n",
    "tag=data['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<front-end><syntax>',\n",
       "       '<functions><performance-tuning><pattern-matching><filtering><function-comparison>',\n",
       "       '<cdf-format>', '<topology><graphics>', '<graphics><plotting>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_num=3000#取词频最高的300个body词\n",
    "tag_num=300#取词频最高的300个tag词\n",
    "tag=tag[0:10000]\n",
    "tag[0:5]#观察一下tag的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tag(sentence):#tag不需要进行单词还原是因为平台会自动完成tagrec部分 推荐正确的词形\n",
    "    sentence=sentence.lower()#所有字母小写\n",
    "    del_estr = string.punctuation + string.digits+string.whitespace  #去除ASCII，标点符号，数字\n",
    "    del_estr=del_estr.replace('-','')#保留- 因为tag里有很多-有用\n",
    "    replace = \" \"*len(del_estr)\n",
    "    tran_tab = str.maketrans(del_estr, replace)\n",
    "    sentence = sentence.translate(tran_tab)#完成上述去除标点符号的功能\n",
    "    words=sentence.split(' ')#根据空格把句子分隔成单词\n",
    "    while '' in words:\n",
    "        words.remove('')#去除为空格的空值\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20805"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2=[]#tag2为经过预处理后的词袋\n",
    "for tagi in tag:\n",
    "    tag2.append(remove_tag(tagi))\n",
    "tag3=[]#tag3为所有的tag之和，用于统计词频\n",
    "for tagi in tag2:\n",
    "    tag3=tag3+tagi\n",
    "len(tag3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "counter = collections.Counter()# 统计单词出现的频率\n",
    "for word in tag3:\n",
    "    counter[word] += 1#词频字典\n",
    "# 按照词频顺序对单词进行排序\n",
    "sorted_word_to_cnt = sorted(counter.items(), key=itemgetter(1), reverse=True)\n",
    "sorted_words = [x[0] for x in sorted_word_to_cnt]\n",
    "import codecs\n",
    "import sys\n",
    "vocab = sorted_words[:tag_num] #只选取前tag_num个tag词汇\n",
    "vocab = [\"<unknown_tag>\"] + vocab#再加上一个unknown词 用来表示样本里低频词汇\n",
    "# 读取词汇表，并建立词汇到单词编号的映射\n",
    "word_to_id = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\n",
    "# 如果出现了被删除的低频词，则替换为\"<unk>\"\n",
    "def get_id(word):\n",
    "    return word_to_id[word] if word in word_to_id else word_to_id[\"<unknown_tag>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag5=[]#tag5是最终数值化表示的tag集合 \n",
    "for word in tag2:\n",
    "    tag4=[]#tag4是每一个post对应的tag集合里的一个单词\n",
    "    for w in word: \n",
    "        tag4=tag4+[get_id(w)]\n",
    "    tag5=tag5+[tag4]\n",
    "tag6=np.array(tag5)#tag6是array化的tag集合 作为代码的输入数据之一\n",
    "len(tag6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<p>From the front end, <code>\\\\[InvisibleApplication]</code> can be entered as <kbd>Esc</kbd> <kbd>@</kbd> <kbd>Esc</kbd>, and is an invisible operator for <code>@</code>!. By an unfortunate combination of key-presses (there may have been a cat involved), this crept up in my code and I spent a great deal of time trying to figure out why in the world <code>f x</code> was being interpreted as <code>f[x]</code>. Example:</p>\\n\\n<p><img src=\"https://i.stack.imgur.com/2Hxll.png\" alt=\"enter image description here\"></p>\\n\\n<p>Now there is no way I could\\'ve spotted this visually. The <code>*Form</code>s weren\\'t of much help either. If you\\'re careful enough, you can see an invisible character between <code>f</code> and <code>x</code> if you move your cursor across the expression. Eventually, I found this out only by looking at the contents of the cell. </p>\\n\\n<p>There\\'s also <code>\\\\[InvisibleSpace]</code>, <code>\\\\[InvisibleComma]</code> and <code>\\\\[ImplicitPlus]</code>, which are analogous to the above. There must be some use for these (perhaps internally), which is why it has been implemented in the first place. I can see the use for invisible space (lets you place superscripts/subscripts without needing anything visible to latch on to), and invisible comma (lets you use indexing like in math). It\\'s the invisible apply that has me wondering...</p>\\n\\n<p>The only advantage I can see is to sort of visually obfuscate the code. Where (or how) is this used (perhaps internally?), and can I disable it? If it\\'s possible to disable, will there be any side effects?</p>\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body=body[0:10000]\n",
    "body[0:1]#观察一下tag的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords \n",
    "wnl = WordNetLemmatizer() \n",
    "sw=stopwords.words('english')#这两步都是在循环前调用为了加快速度\n",
    "def remove_body(sentence):\n",
    "    cleanr = re.compile('<.*?>')#去除html标签\n",
    "    sentence = re.sub(cleanr, ' ', sentence)#去除html标签\n",
    "    sentence=sentence.lower()#字母小写化\n",
    "    del_estr = string.punctuation + string.digits+string.whitespace  # 去除ASCII 标点符号，数字\n",
    "    replace = \" \"*len(del_estr)\n",
    "    tran_tab = str.maketrans(del_estr, replace)\n",
    "    sentence = sentence.translate(tran_tab)#完成上述去除标点符号的功能\n",
    "    #去除stopwords 并把句子转换成单词的列表\n",
    "    words= [w for w in sentence.split(' ') if w not in sw]\n",
    "    while '' in words:\n",
    "        words.remove('')#去除list里的空值\n",
    "    while 'n' in words:\n",
    "        words.remove('n')#去除list里的p\n",
    "    while 'f' in words:\n",
    "        words.remove('f')#去除list里的f\n",
    "    while 'x' in words:\n",
    "        words.remove('x')#去除list里的x\n",
    "    #不知道invisible之类的需要删除吗\n",
    "    record=[]#这个循环在做词形还原\n",
    "    for i in words:\n",
    "        record=record+[wnl.lemmatize(i)]\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body2=[]#body2用于对每条body完成刚刚的数据预处理操作\n",
    "for bodyi in body:\n",
    "    body2.append(remove_body(bodyi))\n",
    "body3=[]#body3是汇总全部的body单词 用于词频统计\n",
    "for bodyi in body2:\n",
    "    body3=body3+bodyi\n",
    "len(body2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import collections\n",
    "from operator import itemgetter\n",
    "# 统计单词出现的频率\n",
    "counter2 = collections.Counter()\n",
    "for word in body3:\n",
    "    counter2[word] += 1#词频字典\n",
    "# 按照词频顺序对单词进行排序\n",
    "sorted_word_to_cnt2 = sorted(counter2.items(), key=itemgetter(1), reverse=True)\n",
    "sorted_words2 = [x[0] for x in sorted_word_to_cnt2]\n",
    "import codecs\n",
    "import sys\n",
    "# 读取词汇表，并建立词汇到单词编号的映射。\n",
    "vocab2 = sorted_words2[:body_num] #只选取前body_num个body词汇\n",
    "vocab2 = [\"unknown\"] + vocab2#再加上一个unknown词 用来表示样本里低频词汇\n",
    "word_to_id2 = {k: v for (k, v) in zip(vocab2, range(len(vocab2)))}\n",
    "# 如果出现了被删除的低频词，则替换为\"<unk>\"\n",
    "def get_id2(word):\n",
    "    return word_to_id2[word] if word in word_to_id2 else word_to_id2[\"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body5=[]#body5是所有body的数值表示\n",
    "for word in body2:\n",
    "    body4=[]#body4是每个body的数值表示\n",
    "    for w in word: \n",
    "        body4=body4+[get_id2(w)]\n",
    "    body5=body5+[body4]\n",
    "body6=np.array(body5)\n",
    "len(body6)#看一眼长度有没有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存为data.npz文件\n",
    "brs=body6#contextual\n",
    "ms=tag6#no useful\n",
    "sfs=tag6#tags \n",
    "np.savez('data.npz',brs= brs, ms = ms,sfs=ms,allow_pickle=True)\n",
    "data=np.load('data.npz',allow_pickle=True)#读取一下试试看\n",
    "len(data['brs'])#再看一看长度有没有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#为了后续的分析 也把tag和body里单词与数值对应的字典保存下来\n",
    "np.save('word_to_id.npy', word_to_id,allow_pickle=True) \n",
    "np.save('word_to_id2.npy', word_to_id2,allow_pickle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
